import argparse
import sys
import time

# Tasks
from projectanalysis.python_repository_analyzer import PythonRepositoryAnalyzer

# Types
from crossflow.projectanalysis import project
from crossflow.projectanalysis import python_repository_analysis_result
from crossflow.projectanalysis import repository
from crossflow.projectanalysis import java_repository_analysis_result
from crossflow.projectanalysis import confirmation

# Streams
from crossflow.projectanalysis.projects import Projects
from crossflow.projectanalysis.repositories import Repositories
from crossflow.projectanalysis.initial_repository_analyses import InitialRepositoryAnalyses
from crossflow.projectanalysis.repository_analysis_results import RepositoryAnalysisResults
from crossflow.projectanalysis.repository_sync_topic import RepositorySyncTopic

# Utility
from crossflow.projectanalysis.projects_analysis_tasks import ProjectsAnalysisTasks
from crossflow.runtime import BuiltinStream, Mode, Workflow
from crossflow.serialization import Serializer, JsonSerializer


class ProjectsAnalysis(Workflow):
    """NOTE: Auto-generated by Workflow2Class on 2019-12-19T16:51:07.797Z    
    Do not edit this class manually
    """

    def __init__(
        self,
        name="",
        instance=None,
        broker_host="localhost",
        stomp_port=61613,
        mode=Mode.WORKER,
        cache=None,
        cache_enabled=True,
        delete_cache=None,
        excluded_tasks=None,
        enable_prefetch=False
    ):
                 
        super().__init__(name=name,
                         instance=instance,
                         broker_host=broker_host,
                         stomp_port=stomp_port,
                         mode=mode,
                         cache=cache,
                         cache_enabled=cache_enabled,
                         delete_cache=delete_cache,
                         excluded_tasks=excluded_tasks,
                         enable_prefetch=False)
                         
        # Streams
        self.projects: Projects = None
        self.repositories: Repositories = None
        self.initialRepositoryAnalyses: InitialRepositoryAnalyses = None
        self.repositoryAnalysisResults: RepositoryAnalysisResults = None
        self.repositorySyncTopic: RepositorySyncTopic = None

        # Tasks
        self.pythonRepositoryAnalyzer = None
        
        # Task creation
        self.tasks = []
        if ProjectsAnalysisTasks.PYTHON_REPOSITORY_ANALYZER not in self._excluded_tasks:
            self.pythonRepositoryAnalyzer = PythonRepositoryAnalyzer()
            self.pythonRepositoryAnalyzer.workflow = self
            self.tasks.append(self.pythonRepositoryAnalyzer)

    def excluded_tasks(self, tasks=[]):
        assert isinstance(tasks, list)
        assert not tasks or [t for t in tasks if isinstance(t, ProjectsAnalysisTasks)]
        self._excluded_tasks = tasks

    def createWorker(self):
        worker = ProjectsAnalysis(Mode.WORKER)
        worker.instance(self._instance)
        return worker


    """
     * Run with initial delay in ms before starting execution (after creating broker
     * if master)
     * 
     * @param delay
    """
    def run(self, delay=0):
        """Run with an initial delay before starting execution

        :param delay: delay in ms before this worker will start running. Defaults to 0
        :type delay: int
        """
        self._delay=delay

        try:
            time.sleep(delay)
            self.connect()
            
            # Initialise Streams
            self.projects = Projects(self, self._enable_prefetch)
            self._active_streams.append(self.projects)
            
            self.repositories = Repositories(self, self._enable_prefetch)
            self._active_streams.append(self.repositories)
            
            self.initialRepositoryAnalyses = InitialRepositoryAnalyses(self, self._enable_prefetch)
            self._active_streams.append(self.initialRepositoryAnalyses)
            
            self.repositoryAnalysisResults = RepositoryAnalysisResults(self, self._enable_prefetch)
            self._active_streams.append(self.repositoryAnalysisResults)
            
            self.repositorySyncTopic = RepositorySyncTopic(self, self._enable_prefetch)
            self._active_streams.append(self.repositorySyncTopic)
            
            if (self.is_worker()):
                if not ProjectsAnalysisTasks.PYTHON_REPOSITORY_ANALYZER in self._excluded_tasks:
                        self.initialRepositoryAnalyses.add_consumer(self.pythonRepositoryAnalyzer, "PythonRepositoryAnalyzer");            
                        self.pythonRepositoryAnalyzer.setRepositoryAnalysisResults(self.repositoryAnalysisResults);
        except Exception as ex:
            self.local_logger.exception("")
            self.report_internal_exception(ex)

    def getProjects(self) -> Projects:
        return self.projects
        
    def getRepositories(self) -> Repositories:
        return self.repositories
        
    def getInitialRepositoryAnalyses(self) -> InitialRepositoryAnalyses:
        return self.initialRepositoryAnalyses
        
    def getRepositoryAnalysisResults(self) -> RepositoryAnalysisResults:
        return self.repositoryAnalysisResults
        
    def getRepositorySyncTopic(self) -> RepositorySyncTopic:
        return self.repositorySyncTopic
        
    def getProjectSource(self):
        return self.projectSource
        
    def getPythonRepositoryAnalyzer(self):
        return self.pythonRepositoryAnalyzer
        
    def getRepositoryAnalysisResultSink(self):
        return self.repositoryAnalysisResultSink
        
    def getJavaRepositoryAnalyzer(self):
        return self.javaRepositoryAnalyzer
        
    def getRepositoryCloner(self):
        return self.repositoryCloner
        
    def _create_serializer(self) -> Serializer:
        return JsonSerializer()

    def _register_custom_serialization_types(self):
        self._serializer.register_type(project.Project)
        self._serializer.register_type(python_repository_analysis_result.PythonRepositoryAnalysisResult)
        self._serializer.register_type(repository.Repository)
        self._serializer.register_type(java_repository_analysis_result.JavaRepositoryAnalysisResult)
        self._serializer.register_type(confirmation.Confirmation)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-name', default='ProjectsAnalysisPython', help='The name of the workflow')
    parser.add_argument('-brokerHost', default='localhost', help='Host of the JMX broker')
    parser.add_argument('-stompPort', default=61613, help='Port to use for stomp based messages')
    parser.add_argument('-instance', default=None, help='The instance of the master (to contribute to)')
    parser.add_argument('-mode', default='WORKER', help='must be one of WORKER or API')
    
    parsedArgs = parser.parse_args(sys.argv[1:len(sys.argv)])
    
    app = ProjectsAnalysis(name=parsedArgs.name,
                      instance=parsedArgs.instance,
                      broker_host=parsedArgs.brokerHost,
                      stomp_port=parsedArgs.stompPort,
                      mode=Mode.enum_from_name(parsedArgs.mode))
                      
    app.run()

    while (not app.terminated):
        time.sleep(0.1)
    print("terminated")
    
